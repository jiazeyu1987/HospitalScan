# åŒ»é™¢å®˜ç½‘è¯†åˆ«çˆ¬è™«ç³»ç»Ÿè®¾è®¡æ–‡æ¡£

**ä½œè€…ï¼š** MiniMax Agent  
**ç‰ˆæœ¬ï¼š** v1.0  
**æ—¥æœŸï¼š** 2025-11-18  
**é¡¹ç›®ï¼š** å…¨å›½åŒ»é™¢å®˜ç½‘æ‰«æä¸æ‹›æŠ•æ ‡ç›‘æ§ç³»ç»Ÿ

---

## ğŸ¯ ä¸€ã€ç³»ç»Ÿæ¦‚è¿°

### 1.1 è®¾è®¡ç›®æ ‡
åŒ»é™¢å®˜ç½‘è¯†åˆ«çˆ¬è™«ç³»ç»Ÿæ—¨åœ¨é€šè¿‡æ™ºèƒ½åŒ–ç®—æ³•ï¼Œè‡ªåŠ¨å‘ç°å’ŒéªŒè¯å…¨å›½åŒ»é™¢å®˜ç½‘ï¼Œä¸ºåç»­çš„æ‹›æŠ•æ ‡ç›‘æ§æä¾›å‡†ç¡®çš„ç›®æ ‡åˆ—è¡¨ã€‚ç³»ç»Ÿé‡‡ç”¨å¤šæ¸ é“æœç´¢ã€çœŸå®æ€§éªŒè¯å’Œæ™ºèƒ½å»é‡çš„ç­–ç•¥ï¼Œç¡®ä¿å‘ç°çš„å®˜ç½‘å‡†ç¡®ç‡é«˜ã€è¦†ç›–é¢å¹¿ã€‚

### 1.2 æ ¸å¿ƒåŠŸèƒ½æ¨¡å—

```python
# ç³»ç»Ÿæ¶æ„æ¦‚è§ˆ
HospitalDiscoverySystem:
â”œâ”€â”€ SearchEngine      # å¤šæ¸ é“æœç´¢å¼•æ“
â”œâ”€â”€ WebsiteVerifier   # å®˜ç½‘çœŸå®æ€§éªŒè¯å™¨
â”œâ”€â”€ AntiCrawler      # åçˆ¬è™«ç­–ç•¥æ¨¡å—
â”œâ”€â”€ Deduplication    # å»é‡ä¸åˆå¹¶æ¨¡å—
â”œâ”€â”€ DataProcessor    # æ•°æ®å¤„ç†æ¨¡å—
â””â”€â”€ QualityController # è´¨é‡æ§åˆ¶å™¨
```

### 1.3 æŠ€æœ¯æµç¨‹

```
åœ°åŒºæ‰«æ â†’ åŒ»é™¢å‘ç° â†’ å®˜ç½‘æœç´¢ â†’ çœŸå®æ€§éªŒè¯ â†’ æ•°æ®å»é‡ â†’ è´¨é‡æ§åˆ¶ â†’ ç»“æœå…¥åº“
```

---

## ğŸ” äºŒã€å¤šæ¸ é“åŒ»é™¢å®˜ç½‘æœç´¢

### 2.1 æœç´¢æ¸ é“è®¾è®¡

#### 2.1.1 æœç´¢å¼•æ“æ¸ é“
```python
class SearchEngine:
    """å¤šæ¸ é“æœç´¢å¼•æ“"""
    
    def __init__(self):
        self.engines = {
            'baidu': BaiduSearchEngine(),
            'bing': BingSearchEngine(),
            'sogou': SogouSearchEngine(),
            'duckduckgo': DuckDuckGoSearchEngine()
        }
        self.config = self._load_config()
    
    def search_hospitals(self, region_name: str, city_name: str = None) -> List[SearchResult]:
        """æ ¹æ®åœ°åŒºæœç´¢åŒ»é™¢"""
        search_queries = self._generate_search_queries(region_name, city_name)
        all_results = []
        
        for query in search_queries:
            for engine_name, engine in self.engines.items():
                try:
                    results = engine.search(query)
                    all_results.extend(results)
                    self._log_search(engine_name, query, len(results))
                except Exception as e:
                    self._log_error(f"æœç´¢å¼•æ“ {engine_name} æœç´¢å¤±è´¥", e)
        
        return self._deduplicate_search_results(all_results)
    
    def _generate_search_queries(self, region_name: str, city_name: str = None) -> List[str]:
        """ç”Ÿæˆæœç´¢å…³é”®è¯ç»„åˆ"""
        queries = []
        base_patterns = [
            f"{region_name} åŒ»é™¢ å®˜ç½‘",
            f"{region_name} äººæ°‘åŒ»é™¢ å®˜ç½‘",
            f"{region_name} ä¸­åŒ»é™¢ å®˜ç½‘",
            f"{region_name} å¦‡å¹¼ä¿å¥é™¢ å®˜ç½‘",
        ]
        
        # å¦‚æœæœ‰åŸå¸‚åï¼Œæ·»åŠ æ›´ç²¾ç¡®çš„æœç´¢
        if city_name:
            city_patterns = [
                f"{city_name} åŒ»é™¢ å®˜ç½‘",
                f"{city_name} äººæ°‘åŒ»é™¢ å®˜ç½‘",
                f"{city_name} å¸‚åŒ»é™¢ å®˜ç½‘",
                f"{city_name} ä¸­å¿ƒåŒ»é™¢ å®˜ç½‘"
            ]
            base_patterns.extend(city_patterns)
        
        return base_patterns
```

#### 2.1.2 å«å¥å§”æ•°æ®æ¸ é“
```python
class NHCSearchEngine:
    """å«å¥å§”æ•°æ®æœç´¢"""
    
    def __init__(self):
        self.data_sources = [
            'http://www.nhc.gov.cn/',
            'http://www.cn-healthcare.com/',
            'http://www.bjhb.gov.cn/',  # åŒ—äº¬å«å¥å§”
            'http://wsjkw.sh.gov.cn/',  # ä¸Šæµ·å«å¥å§”
        ]
    
    def get_hospitals_from_nhc(self, region_code: str) -> List[HospitalInfo]:
        """ä»å«å¥å§”æ•°æ®è·å–åŒ»é™¢ä¿¡æ¯"""
        hospitals = []
        
        # æ¨¡æ‹Ÿå«å¥å§”æ•°æ®æºè®¿é—®
        try:
            # è¿™é‡Œå¯ä»¥å®ç°å…·ä½“çš„å«å¥å§”ç½‘ç«™çˆ¬å–é€»è¾‘
            data = self._fetch_nhc_data(region_code)
            hospitals = self._parse_nhc_hospitals(data)
        except Exception as e:
            self.logger.error(f"å«å¥å§”æ•°æ®è·å–å¤±è´¥: {e}")
        
        return hospitals
    
    def _fetch_nhc_data(self, region_code: str) -> Dict:
        """è·å–å«å¥å§”æ•°æ®"""
        # å®é™…å®ç°ä¸­éœ€è¦æ ¹æ®å…·ä½“çš„å«å¥å§”ç½‘ç«™ç»“æ„æ¥ç¼–å†™
        # è¿™é‡Œæä¾›æ¨¡æ‹Ÿæ•°æ®ç»“æ„
        return {
            'hospitals': [
                {
                    'name': f'{region_code}äººæ°‘åŒ»é™¢',
                    'type': 'public',
                    'level': 'ä¸‰çº§ç”²ç­‰',
                    'website': f'http://www.{region_code}rmyy.cn'
                }
            ]
        }
```

#### 2.1.3 æ”¿åºœå®˜ç½‘æ¸ é“
```python
class GovernmentSearchEngine:
    """æ”¿åºœå®˜ç½‘æœç´¢"""
    
    def search_government_hospitals(self, region_name: str) -> List[SearchResult]:
        """ä»æ”¿åºœå®˜ç½‘æœç´¢åŒ»é™¢ä¿¡æ¯"""
        government_sites = self._get_government_sites(region_name)
        results = []
        
        for site_info in government_sites:
            try:
                results.extend(self._search_in_government_site(site_info))
            except Exception as e:
                self.logger.error(f"æ”¿åºœç½‘ç«™ {site_info['url']} æœç´¢å¤±è´¥: {e}")
        
        return results
    
    def _get_government_sites(self, region_name: str) -> List[Dict]:
        """è·å–æ”¿åºœç›¸å…³ç½‘ç«™"""
        return [
            {
                'url': f'http://www.{region_name}.gov.cn/',
                'name': f'{region_name}æ”¿åºœç½‘',
                'type': 'government'
            },
            {
                'url': f'http://wjw.{region_name}.gov.cn/',
                'name': f'{region_name}å«å¥å§”',
                'type': 'health_commission'
            }
        ]
```

### 2.2 æœç´¢ç»“æœæ ‡å‡†åŒ–

```python
@dataclass
class SearchResult:
    """æ ‡å‡†åŒ–æœç´¢ç»“æœ"""
    hospital_name: str
    website_url: str
    source: str  # æœç´¢æ¥æº
    rank: int    # æœç´¢æ’å
    confidence: float  # åŒ¹é…å¯ä¿¡åº¦
    search_query: str
    timestamp: datetime
    additional_info: Dict = field(default_factory=dict)

class SearchResultProcessor:
    """æœç´¢ç»“æœå¤„ç†å™¨"""
    
    def process_raw_results(self, raw_results: List) -> List[SearchResult]:
        """å¤„ç†åŸå§‹æœç´¢ç»“æœ"""
        processed_results = []
        
        for result in raw_results:
            processed = self._standardize_result(result)
            if self._validate_result(processed):
                processed_results.append(processed)
        
        return self._sort_by_confidence(processed_results)
    
    def _standardize_result(self, raw_result) -> SearchResult:
        """æ ‡å‡†åŒ–å•ä¸ªæœç´¢ç»“æœ"""
        return SearchResult(
            hospital_name=raw_result.get('title', '').strip(),
            website_url=raw_result.get('url', '').strip(),
            source=raw_result.get('source', 'unknown'),
            rank=raw_result.get('rank', 0),
            confidence=self._calculate_confidence(raw_result),
            search_query=raw_result.get('query', ''),
            timestamp=datetime.now(),
            additional_info=raw_result.get('info', {})
        )
    
    def _calculate_confidence(self, result: Dict) -> float:
        """è®¡ç®—æœç´¢ç»“æœå¯ä¿¡åº¦"""
        confidence = 0.5  # åŸºç¡€åˆ†æ•°
        
        # æ ¹æ®URLåˆ¤æ–­
        url = result.get('url', '').lower()
        if '.gov.cn' in url:
            confidence += 0.3  # æ”¿åºœç½‘ç«™
        elif any(keyword in url for keyword in ['hospital', 'yy', 'rmyy']):
            confidence += 0.2  # åŒ…å«åŒ»é™¢å…³é”®è¯
        
        # æ ¹æ®æ ‡é¢˜åˆ¤æ–­
        title = result.get('title', '').lower()
        hospital_keywords = ['åŒ»é™¢', 'äººæ°‘åŒ»é™¢', 'ä¸­åŒ»é™¢', 'å«ç”Ÿé™¢', 'å«ç”Ÿé™¢']
        for keyword in hospital_keywords:
            if keyword in title:
                confidence += 0.1
        
        return min(confidence, 1.0)
```

---

## ğŸ” ä¸‰ã€åŒ»é™¢å®˜ç½‘çœŸå®æ€§åˆ¤å®šç®—æ³•

### 3.1 åˆ¤å®šæ ‡å‡†ä½“ç³»

```python
class WebsiteVerifier:
    """åŒ»é™¢å®˜ç½‘çœŸå®æ€§éªŒè¯å™¨"""
    
    def __init__(self):
        self.criteria = self._load_verification_criteria()
        self.content_analyzer = ContentAnalyzer()
        self.domain_analyzer = DomainAnalyzer()
    
    def verify_website(self, search_result: SearchResult) -> VerificationResult:
        """éªŒè¯ç½‘ç«™çœŸå®æ€§"""
        result = VerificationResult(
            url=search_result.website_url,
            hospital_name=search_result.hospital_name,
            overall_score=0.0,
            criteria_scores={},
            is_verified=False,
            verification_details={}
        )
        
        try:
            # 1. åŸºç¡€éªŒè¯
            result.criteria_scores['basic'] = self._verify_basic_criteria(search_result)
            
            # 2. å†…å®¹éªŒè¯
            result.criteria_scores['content'] = self._verify_content_criteria(search_result)
            
            # 3. åŸŸåéªŒè¯
            result.criteria_scores['domain'] = self._verify_domain_criteria(search_result)
            
            # 4. ç»“æ„éªŒè¯
            result.criteria_scores['structure'] = self._verify_structure_criteria(search_result)
            
            # 5. ç»¼åˆè¯„åˆ†
            result.overall_score = self._calculate_overall_score(result.criteria_scores)
            result.is_verified = result.overall_score >= 0.7
            
            result.verification_details = {
                'verification_time': datetime.now(),
                'methodology': 'multi_criteria_verification',
                'recommendation': self._get_recommendation(result.overall_score)
            }
            
        except Exception as e:
            result.verification_details['error'] = str(e)
        
        return result
    
    def _verify_basic_criteria(self, result: SearchResult) -> float:
        """åŸºç¡€éªŒè¯"""
        score = 0.0
        
        # URLæœ‰æ•ˆæ€§æ£€æŸ¥
        if self._is_valid_url(result.website_url):
            score += 0.3
        
        # HTTPçŠ¶æ€æ£€æŸ¥
        if self._check_http_status(result.website_url):
            score += 0.3
        
        # å“åº”æ—¶é—´æ£€æŸ¥
        response_time = self._check_response_time(result.website_url)
        if response_time < 5.0:  # 5ç§’å†…
            score += 0.2
        
        # HTTPSæ£€æŸ¥
        if result.website_url.startswith('https://'):
            score += 0.2
        
        return min(score, 1.0)
    
    def _verify_content_criteria(self, result: SearchResult) -> float:
        """å†…å®¹éªŒè¯"""
        score = 0.0
        
        try:
            # è·å–é¡µé¢å†…å®¹
            content = self.content_analyzer.get_page_content(result.website_url)
            
            # åŒ»é™¢ç‰¹å¾å…³é”®è¯æ£€æŸ¥
            hospital_keywords = [
                'åŒ»é™¢', 'åŒ»ç–—', 'ç§‘å®¤', 'åŒ»ç”Ÿ', 'é—¨è¯Š', 'ä½é™¢',
                'äººæ°‘åŒ»é™¢', 'ä¸­åŒ»é™¢', 'å«ç”Ÿé™¢', 'è¯Šç–—', 'ä½é™¢éƒ¨'
            ]
            
            keyword_matches = sum(1 for keyword in hospital_keywords 
                                if keyword in content.lower())
            score += min(keyword_matches * 0.1, 0.4)
            
            # åŒ»é™¢åŸºæœ¬ä¿¡æ¯æ£€æŸ¥
            if any(info in content.lower() for info in ['åœ°å€', 'ç”µè¯', 'è”ç³»æ–¹å¼']):
                score += 0.2
            
            # æ‹›æŠ•æ ‡ç›¸å…³æ ç›®æ£€æŸ¥
            if any(section in content.lower() for section in 
                  ['æ‹›æ ‡', 'é‡‡è´­', 'å…¬ç¤º', 'å…¬å‘Š', 'ä¿¡æ¯å‘å¸ƒ']):
                score += 0.2
            
            # åŒ»é™¢ç®€ä»‹æ£€æŸ¥
            if len(content) > 1000:  # æœ‰è¶³å¤Ÿçš„å†…å®¹
                score += 0.2
            
        except Exception as e:
            self.logger.warning(f"å†…å®¹éªŒè¯å¤±è´¥: {e}")
            score = 0.1
        
        return min(score, 1.0)
    
    def _verify_domain_criteria(self, result: SearchResult) -> float:
        """åŸŸåéªŒè¯"""
        score = 0.0
        
        domain = self._extract_domain(result.website_url)
        
        # åŸŸåå¯ä¿¡åº¦è¯„ä¼°
        if domain.endswith('.gov.cn'):
            score += 0.4  # æ”¿åºœåŸŸå
        elif domain.endswith('.org.cn'):
            score += 0.3  # æœºæ„åŸŸå
        elif any(suffix in domain for suffix in ['.cn', '.com', '.net']):
            score += 0.2
        
        # åŒ»é™¢ç›¸å…³åŸŸåå…³é”®è¯
        hospital_keywords = ['hospital', 'yy', 'rmyy', 'medical']
        if any(keyword in domain.lower() for keyword in hospital_keywords):
            score += 0.3
        
        # åŸŸåé•¿åº¦å’Œè§„èŒƒæ€§
        if 10 <= len(domain) <= 50:  # åˆç†çš„åŸŸåé•¿åº¦
            score += 0.1
        
        # é¿å…çš„åŸŸåæ¨¡å¼
        suspicious_patterns = [
            'baidu', 'qq', 'weixin', 'taobao', '114', 'jia', 
            'sou', 'so', 'search'
        ]
        if any(pattern in domain.lower() for pattern in suspicious_patterns):
            score -= 0.5  # æ˜æ˜¾ä¸æ˜¯åŒ»é™¢å®˜ç½‘
        
        return max(score, 0.0)
    
    def _verify_structure_criteria(self, result: SearchResult) -> float:
        """ç»“æ„éªŒè¯"""
        score = 0.0
        
        try:
            soup = self.content_analyzer.get_page_soup(result.website_url)
            
            # å¿…è¦é¡µé¢å…ƒç´ æ£€æŸ¥
            essential_elements = [
                'å¯¼èˆªèœå•', 'ä¸»è¦å†…å®¹åŒº', 'é¡µè„šä¿¡æ¯', 'è”ç³»æ–¹å¼'
            ]
            
            for element in essential_elements:
                if self._check_page_element(soup, element):
                    score += 0.1
            
            # åŒ»é™¢ç§‘å®¤é¡µé¢æ£€æŸ¥
            if self._has_department_links(soup):
                score += 0.2
            
            # åŒ»é™¢æ–°é—»/å…¬å‘Šé¡µé¢æ£€æŸ¥
            if self._has_news_section(soup):
                score += 0.2
            
            # åŒ»é™¢æ¦‚å†µ/ä»‹ç»é¡µé¢æ£€æŸ¥
            if self._has_about_section(soup):
                score += 0.2
            
        except Exception as e:
            self.logger.warning(f"ç»“æ„éªŒè¯å¤±è´¥: {e}")
            score = 0.1
        
        return min(score, 1.0)
    
    def _load_verification_criteria(self) -> Dict:
        """åŠ è½½éªŒè¯æ ‡å‡†"""
        return {
            'basic_weight': 0.25,
            'content_weight': 0.35,
            'domain_weight': 0.25,
            'structure_weight': 0.15,
            'minimum_score': 0.7,
            'high_confidence_score': 0.85
        }
```

### 3.2 å†…å®¹åˆ†æå™¨

```python
class ContentAnalyzer:
    """é¡µé¢å†…å®¹åˆ†æå™¨"""
    
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'HospitalTenderMonitor/1.0 (Research Purpose Only)'
        })
    
    def get_page_content(self, url: str) -> str:
        """è·å–é¡µé¢æ–‡æœ¬å†…å®¹"""
        try:
            response = self.session.get(url, timeout=10)
            response.raise_for_status()
            
            # è§£æHTML
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # ç§»é™¤è„šæœ¬å’Œæ ·å¼å…ƒç´ 
            for script in soup(["script", "style"]):
                script.decompose()
            
            # è·å–æ–‡æœ¬å†…å®¹
            text = soup.get_text()
            # æ¸…ç†æ–‡æœ¬
            text = ' '.join(text.split())
            
            return text
            
        except Exception as e:
            self.logger.error(f"è·å–é¡µé¢å†…å®¹å¤±è´¥ {url}: {e}")
            return ""
    
    def get_page_soup(self, url: str) -> BeautifulSoup:
        """è·å–é¡µé¢BeautifulSoupå¯¹è±¡"""
        response = self.session.get(url, timeout=10)
        response.raise_for_status()
        return BeautifulSoup(response.content, 'html.parser')
    
    def extract_hospital_info(self, soup: BeautifulSoup, url: str) -> Dict:
        """æå–åŒ»é™¢ä¿¡æ¯"""
        info = {
            'hospital_name': self._extract_hospital_name(soup),
            'address': self._extract_address(soup),
            'phone': self._extract_phone(soup),
            'departments': self._extract_departments(soup),
            'services': self._extract_services(soup),
            'has_tender_section': self._check_tender_section(soup)
        }
        
        return info
    
    def _extract_hospital_name(self, soup: BeautifulSoup) -> str:
        """æå–åŒ»é™¢åç§°"""
        # ä¼˜å…ˆçº§ï¼štitle > h1 > meta title
        title = soup.find('title')
        if title and title.get_text().strip():
            return title.get_text().strip()
        
        h1 = soup.find('h1')
        if h1 and h1.get_text().strip():
            return h1.get_text().strip()
        
        # ä»metaæ ‡ç­¾æå–
        meta_title = soup.find('meta', {'name': 'title'})
        if meta_title and meta_title.get('content'):
            return meta_title['content'].strip()
        
        return ""
    
    def _extract_address(self, soup: BeautifulSoup) -> str:
        """æå–åœ°å€ä¿¡æ¯"""
        address_patterns = [
            r'åœ°å€[ï¼š:]\s*([^\n\r<]+)',
            r'åœ°å€[ï¼š:]\s*([^<\n]+)',
            r'ä½äº[ï¼š:]?\s*([^\n\r<]+)'
        ]
        
        page_text = soup.get_text()
        for pattern in address_patterns:
            match = re.search(pattern, page_text)
            if match:
                return match.group(1).strip()
        
        return ""
    
    def _extract_phone(self, soup: BeautifulSoup) -> str:
        """æå–ç”µè¯å·ç """
        phone_patterns = [
            r'ç”µè¯[ï¼š:]?\s*(\d{3,4}[- ]?\d{7,8})',
            r'è”ç³»ç”µè¯[ï¼š:]?\s*(\d{3,4}[- ]?\d{7,8})',
            r'TEL[ï¼š:]?\s*(\d{3,4}[- ]?\d{7,8})'
        ]
        
        page_text = soup.get_text()
        for pattern in phone_patterns:
            match = re.search(pattern, page_text)
            if match:
                return match.group(1).strip()
        
        return ""
    
    def _check_tender_section(self, soup: BeautifulSoup) -> bool:
        """æ£€æŸ¥æ˜¯å¦æœ‰æ‹›æŠ•æ ‡ç›¸å…³æ ç›®"""
        tender_keywords = [
            'æ‹›æ ‡', 'é‡‡è´­', 'å…¬ç¤º', 'å…¬å‘Š', 'ä¿¡æ¯å‘å¸ƒ', 
            'æ‹›æ ‡é‡‡è´­', 'æ‹›é‡‡ä¿¡æ¯', 'ä¸­æ ‡å…¬ç¤º'
        ]
        
        page_text = soup.get_text().lower()
        return any(keyword in page_text for keyword in tender_keywords)
```

---

## ğŸ›¡ï¸ å››ã€åçˆ¬è™«ç­–ç•¥

### 4.1 åŸºç¡€åçˆ¬è™«ç­–ç•¥

```python
class AntiCrawler:
    """åçˆ¬è™«ç­–ç•¥ç®¡ç†å™¨"""
    
    def __init__(self, config: Dict):
        self.config = config
        self.user_agents = self._load_user_agents()
        self.request_history = []
        self.proxy_pool = []
    
    def get_request_headers(self, url: str = None) -> Dict:
        """ç”Ÿæˆè¯·æ±‚å¤´"""
        headers = {
            'User-Agent': random.choice(self.user_agents),
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'zh-CN,zh;q=0.8,en-US;q=0.5,en;q=0.3',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1'
        }
        
        # æ ¹æ®ç›®æ ‡ç½‘ç«™è°ƒæ•´è¯·æ±‚å¤´
        if url and '.gov.cn' in url:
            headers['Accept'] = 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8'
        
        return headers
    
    def wait_between_requests(self, domain: str = None) -> None:
        """è¯·æ±‚é—´éš”æ§åˆ¶"""
        min_delay = self.config.get('min_request_delay', 2)
        max_delay = self.config.get('max_request_delay', 5)
        
        if domain:
            # åŒä¸€åŸŸåçš„ç‰¹æ®Šå¤„ç†
            last_request = self._get_last_request_for_domain(domain)
            if last_request:
                elapsed = (datetime.now() - last_request).total_seconds()
                if elapsed < min_delay:
                    sleep_time = min_delay - elapsed
                    time.sleep(sleep_time)
        else:
            # å…¨å±€å»¶è¿Ÿ
            delay = random.uniform(min_delay, max_delay)
            time.sleep(delay)
    
    def handle_request_failure(self, url: str, error: Exception) -> bool:
        """å¤„ç†è¯·æ±‚å¤±è´¥"""
        error_type = type(error).__name__
        
        if error_type in ['ConnectionError', 'Timeout']:
            return True  # é‡è¯•
        elif error_type == 'HTTPError':
            if hasattr(error, 'response') and error.response.status_code == 403:
                # å¯èƒ½è¢«å°ï¼Œæ¢ä»£ç†æˆ–å»¶è¿Ÿ
                time.sleep(30)
                return False  # ä¸é‡è¯•ï¼Œéœ€è¦ç­–ç•¥è°ƒæ•´
        elif error_type == 'CaptchaError':
            # éªŒè¯ç ï¼Œéœ€è¦äººå·¥å¤„ç†æˆ–ä½¿ç”¨éªŒè¯ç è¯†åˆ«æœåŠ¡
            self._handle_captcha_error(url)
            return False
        
        return True  # é»˜è®¤é‡è¯•
    
    def _load_user_agents(self) -> List[str]:
        """åŠ è½½User-Agentæ± """
        return [
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:89.0) Gecko/20100101 Firefox/89.0',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:89.0) Gecko/20100101 Firefox/89.0',
            'Mozilla/5.0 (X11; Linux x86_64; rv:89.0) Gecko/20100101 Firefox/89.0',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36 Edg/92.0.902.55'
        ]
```

### 4.2 æ™ºèƒ½é‡è¯•æœºåˆ¶

```python
class RetryManager:
    """æ™ºèƒ½é‡è¯•ç®¡ç†å™¨"""
    
    def __init__(self):
        self.retry_strategies = {
            'exponential_backoff': self._exponential_backoff,
            'linear_backoff': self._linear_backoff,
            'fixed_interval': self._fixed_interval
        }
    
    def execute_with_retry(self, func, *args, **kwargs) -> Any:
        """æ‰§è¡Œå¸¦é‡è¯•çš„å‡½æ•°"""
        max_retries = kwargs.get('max_retries', 3)
        strategy = kwargs.get('retry_strategy', 'exponential_backoff')
        
        for attempt in range(max_retries + 1):
            try:
                return func(*args, **kwargs)
            except Exception as e:
                if attempt == max_retries:
                    raise e
                
                # è®¡ç®—ç­‰å¾…æ—¶é—´
                wait_time = self._calculate_wait_time(attempt, strategy)
                time.sleep(wait_time)
                
                # è®°å½•é‡è¯•ä¿¡æ¯
                self._log_retry(attempt, max_retries, str(e))
    
    def _calculate_wait_time(self, attempt: int, strategy: str) -> float:
        """è®¡ç®—ç­‰å¾…æ—¶é—´"""
        base_delay = 2
        multiplier = 2
        
        if strategy == 'exponential_backoff':
            return base_delay * (multiplier ** attempt)
        elif strategy == 'linear_backoff':
            return base_delay * (attempt + 1)
        else:  # fixed_interval
            return base_delay
```

---

## ğŸ”„ äº”ã€å»é‡ä¸å¢é‡æ›´æ–°æœºåˆ¶

### 5.1 æ•°æ®å»é‡ç®—æ³•

```python
class DeduplicationManager:
    """æ•°æ®å»é‡ç®¡ç†å™¨"""
    
    def __init__(self, db_path: str):
        self.db_path = db_path
        self.similarity_threshold = 0.85
        self.domain_cache = {}
    
    def deduplicate_hospitals(self, new_hospitals: List[HospitalInfo]) -> List[HospitalInfo]:
        """åŒ»é™¢æ•°æ®å»é‡"""
        # è·å–å·²å­˜åœ¨çš„åŒ»é™¢æ•°æ®
        existing_hospitals = self._get_existing_hospitals()
        
        deduplicated = []
        for new_hospital in new_hospitals:
            # æŸ¥æ‰¾ç›¸ä¼¼è®°å½•
            similar_hospitals = self._find_similar_hospitals(
                new_hospital, existing_hospitals
            )
            
            if similar_hospitals:
                # é€‰æ‹©æœ€ä¼˜è®°å½•
                best_match = self._select_best_match(new_hospital, similar_hospitals)
                updated_hospital = self._merge_hospital_data(new_hospital, best_match)
                deduplicated.append(updated_hospital)
            else:
                deduplicated.append(new_hospital)
        
        return deduplicated
    
    def _find_similar_hospitals(self, new_hospital: HospitalInfo, 
                              existing_hospitals: List[HospitalInfo]) -> List[HospitalInfo]:
        """æŸ¥æ‰¾ç›¸ä¼¼åŒ»é™¢"""
        similar = []
        
        for existing in existing_hospitals:
            # 1. åç§°ç›¸ä¼¼åº¦æ£€æŸ¥
            name_similarity = self._calculate_name_similarity(
                new_hospital.name, existing.name
            )
            
            # 2. åŸŸåç›¸ä¼¼åº¦æ£€æŸ¥
            domain_similarity = self._calculate_domain_similarity(
                new_hospital.website_url, existing.website_url
            )
            
            # 3. åœ°åŒºåŒ¹é…æ£€æŸ¥
            region_match = (new_hospital.region_id == existing.region_id)
            
            # 4. ç»¼åˆè¯„åˆ†
            total_score = (name_similarity * 0.4 + 
                          domain_similarity * 0.3 + 
                          (0.3 if region_match else 0))
            
            if total_score >= self.similarity_threshold:
                similar.append((existing, total_score))
        
        # æŒ‰ç›¸ä¼¼åº¦æ’åº
        similar.sort(key=lambda x: x[1], reverse=True)
        return [item[0] for item in similar]
    
    def _calculate_name_similarity(self, name1: str, name2: str) -> float:
        """è®¡ç®—åŒ»é™¢åç§°ç›¸ä¼¼åº¦"""
        # ä½¿ç”¨ç¼–è¾‘è·ç¦»ç®—æ³•
        if name1 == name2:
            return 1.0
        
        # é¢„å¤„ç†
        name1_clean = self._clean_hospital_name(name1)
        name2_clean = self._clean_hospital_name(name2)
        
        # å®Œå…¨åŒ¹é…
        if name1_clean == name2_clean:
            return 1.0
        
        # æ¨¡ç³ŠåŒ¹é…
        similarity = difflib.SequenceMatcher(None, name1_clean, name2_clean).ratio()
        
        # åŒ…å«åŒ¹é…
        if name1_clean in name2_clean or name2_clean in name1_clean:
            similarity = max(similarity, 0.8)
        
        return similarity
    
    def _clean_hospital_name(self, name: str) -> str:
        """æ¸…ç†åŒ»é™¢åç§°"""
        # ç§»é™¤å¸¸è§åç¼€
        suffixes_to_remove = [
            'äººæ°‘åŒ»é™¢', 'åŒ»é™¢', 'å«ç”Ÿé™¢', 'è¯Šæ‰€', 'åŒ»ç–—ä¸­å¿ƒ',
            'å«ç”ŸæœåŠ¡ä¸­å¿ƒ', 'ç¤¾åŒºå«ç”ŸæœåŠ¡ä¸­å¿ƒ', 'ä¸­åŒ»é™¢', 'å«ç”Ÿé™¢'
        ]
        
        cleaned = name.strip()
        for suffix in suffixes_to_remove:
            if cleaned.endswith(suffix):
                cleaned = cleaned[:-len(suffix)]
        
        # ç§»é™¤ç‰¹æ®Šå­—ç¬¦
        cleaned = re.sub(r'[ï¼ˆï¼‰()ã€ï¼Œ,\s]', '', cleaned)
        
        return cleaned
    
    def _calculate_domain_similarity(self, url1: str, url2: str) -> float:
        """è®¡ç®—åŸŸåç›¸ä¼¼åº¦"""
        if not url1 or not url2:
            return 0.0
        
        domain1 = self._extract_domain(url1)
        domain2 = self._extract_domain(url2)
        
        if domain1 == domain2:
            return 1.0
        
        # æå–åŸŸåå…³é”®è¯
        keywords1 = self._extract_domain_keywords(domain1)
        keywords2 = self._extract_domain_keywords(domain2)
        
        # è®¡ç®—å…³é”®è¯é‡å åº¦
        overlap = len(set(keywords1) & set(keywords2))
        total = len(set(keywords1) | set(keywords2))
        
        return overlap / total if total > 0 else 0.0
    
    def _extract_domain_keywords(self, domain: str) -> List[str]:
        """æå–åŸŸåå…³é”®è¯"""
        # ç§»é™¤åŸŸååç¼€
        domain = domain.replace('.cn', '').replace('.com', '').replace('.org', '')
        
        # æå–æ‹¼éŸ³
        pinyin = pypinyin.lazy_pinyin(domain)
        
        # æå–å…³é”®è¯
        keywords = []
        for part in domain.split('.'):
            if len(part) > 1:
                keywords.extend([part] + pypinyin.lazy_pinyin(part))
        
        return [kw for kw in keywords if len(kw) > 1]
    
    def _merge_hospital_data(self, new_hospital: HospitalInfo, 
                           existing_hospital: HospitalInfo) -> HospitalInfo:
        """åˆå¹¶åŒ»é™¢æ•°æ®"""
        merged = HospitalInfo()
        
        # ä¿ç•™å·²æœ‰çš„åŸºç¡€ä¿¡æ¯
        merged.id = existing_hospital.id
        merged.name = existing_hospital.name
        merged.region_id = existing_hospital.region_id
        
        # æ›´æ–°å®˜ç½‘URLï¼ˆä¿ç•™æ›´å¯ä¿¡çš„ï¼‰
        if self._is_more_trustworthy_url(new_hospital.website_url, existing_hospital.website_url):
            merged.website_url = new_hospital.website_url
            merged.is_https = new_hospital.is_https
        else:
            merged.website_url = existing_hospital.website_url
            merged.is_https = existing_hospital.is_https
        
        # åˆå¹¶å…¶ä»–ä¿¡æ¯
        merged.description = new_hospital.description or existing_hospital.description
        merged.phone = new_hospital.phone or existing_hospital.phone
        merged.address = new_hospital.address or existing_hospital.address
        
        # æ›´æ–°æ—¶é—´
        merged.updated_at = datetime.now()
        
        return merged
    
    def _is_more_trustworthy_url(self, url1: str, url2: str) -> bool:
        """åˆ¤æ–­å“ªä¸ªURLæ›´å¯ä¿¡"""
        trust_scores = {
            'https': 2,
            '.gov.cn': 3,
            '.org.cn': 2,
            '.cn': 1
        }
        
        score1 = sum(score for pattern, score in trust_scores.items() if pattern in url1)
        score2 = sum(score for pattern, score in trust_scores.items() if pattern in url2)
        
        return score1 > score2
```

### 5.2 å¢é‡æ›´æ–°æœºåˆ¶

```python
class IncrementalUpdateManager:
    """å¢é‡æ›´æ–°ç®¡ç†å™¨"""
    
    def __init__(self, db_path: str):
        self.db_path = db_path
        self.update_log = UpdateLog()
    
    def check_for_updates(self) -> UpdateCheckResult:
        """æ£€æŸ¥å¢é‡æ›´æ–°"""
        result = UpdateCheckResult()
        
        try:
            # 1. æ£€æŸ¥åŒ»é™¢æ–°å¢
            result.new_hospitals = self._check_new_hospitals()
            
            # 2. æ£€æŸ¥åŒ»é™¢ä¿¡æ¯å˜æ›´
            result.modified_hospitals = self._check_modified_hospitals()
            
            # 3. æ£€æŸ¥åŒ»é™¢å®˜ç½‘æ›´æ–°
            result.website_updates = self._check_website_updates()
            
            # 4. æ£€æŸ¥åŒ»é™¢çŠ¶æ€å˜æ›´
            result.status_changes = self._check_status_changes()
            
        except Exception as e:
            result.error = str(e)
        
        return result
    
    def _check_new_hospitals(self) -> List[HospitalInfo]:
        """æ£€æŸ¥æ–°å¢åŒ»é™¢"""
        # ä»æœç´¢å¼•æ“è·å–æœ€æ–°æ•°æ®
        search_engine = SearchEngine()
        regions_to_check = self._get_regions_needing_scan()
        
        new_hospitals = []
        for region in regions_to_check:
            try:
                # æœç´¢è¯¥åœ°åŒºçš„æ–°åŒ»é™¢
                found_hospitals = search_engine.search_hospitals(
                    region['name'], region.get('cities', [])
                )
                
                # éªŒè¯å¹¶è¿‡æ»¤å·²æœ‰è®°å½•
                for hospital in found_hospitals:
                    if not self._hospital_exists(hospital):
                        new_hospitals.append(hospital)
                        
            except Exception as e:
                self.logger.error(f"æ£€æŸ¥åœ°åŒº {region['name']} æ–°åŒ»é™¢å¤±è´¥: {e}")
        
        return new_hospitals
    
    def _check_modified_hospitals(self) -> List[HospitalChange]:
        """æ£€æŸ¥åŒ»é™¢ä¿¡æ¯å˜æ›´"""
        changes = []
        
        # è·å–éœ€è¦æ›´æ–°çš„åŒ»é™¢åˆ—è¡¨
        hospitals_to_update = self._get_hospitals_needing_update()
        
        for hospital in hospitals_to_update:
            try:
                # é‡æ–°è·å–åŒ»é™¢ä¿¡æ¯
                current_info = self._fetch_current_hospital_info(hospital.website_url)
                
                # æ¯”è¾ƒä¿¡æ¯å·®å¼‚
                diff = self._compare_hospital_info(hospital, current_info)
                if diff.has_changes():
                    changes.append(diff)
                    
            except Exception as e:
                self.logger.error(f"æ£€æŸ¥åŒ»é™¢ {hospital.name} å˜æ›´å¤±è´¥: {e}")
        
        return changes
    
    def _get_hospitals_needing_update(self) -> List[HospitalInfo]:
        """è·å–éœ€è¦æ›´æ–°çš„åŒ»é™¢åˆ—è¡¨"""
        conn = sqlite3.connect(self.db_path)
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()
        
        # æŸ¥æ‰¾éœ€è¦æ›´æ–°çš„åŒ»é™¢ï¼ˆåŸºäºæœ€åæ‰«ææ—¶é—´ï¼‰
        cutoff_date = datetime.now() - timedelta(days=30)  # 30å¤©æœªæ›´æ–°
        
        cursor.execute("""
            SELECT * FROM hospitals 
            WHERE last_scan_time IS NULL OR last_scan_time < ?
            ORDER BY last_scan_time ASC NULLS FIRST
            LIMIT 100  -- é™åˆ¶æ¯æ¬¡æ›´æ–°æ•°é‡
        """, (cutoff_date,))
        
        hospitals = []
        for row in cursor.fetchall():
            hospital = self._row_to_hospital_info(row)
            hospitals.append(hospital)
        
        conn.close()
        return hospitals
```

---

## ğŸ¢ å…­ã€åŒ»é™¢ä¿¡æ¯CRUDæ¥å£

### 6.1 åŒ»é™¢ç®¡ç†æœåŠ¡

```python
class HospitalService:
    """åŒ»é™¢ç®¡ç†æœåŠ¡"""
    
    def __init__(self, db_path: str):
        self.db_path = db_path
        self.search_engine = SearchEngine()
        self.verifier = WebsiteVerifier()
        self.deduplicator = DeduplicationManager(db_path)
        self.logger = logging.getLogger(__name__)
    
    def create_hospital(self, hospital_data: Dict) -> HospitalInfo:
        """åˆ›å»ºåŒ»é™¢è®°å½•"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        try:
            # 1. æ•°æ®éªŒè¯
            hospital = self._validate_hospital_data(hospital_data)
            
            # 2. å®˜ç½‘éªŒè¯ï¼ˆå¦‚æœæä¾›ï¼‰
            if hospital.website_url:
                verification_result = self.verifier.verify_website(
                    SearchResult(
                        hospital_name=hospital.name,
                        website_url=hospital.website_url,
                        source='manual',
                        rank=0,
                        confidence=1.0,
                        search_query='',
                        timestamp=datetime.now()
                    )
                )
                hospital.verified = verification_result.is_verified
            
            # 3. æ’å…¥æ•°æ®åº“
            cursor.execute("""
                INSERT INTO hospitals (
                    name, website_url, hospital_type, region_id, 
                    address, phone, description, status, verified,
                    created_at, updated_at
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                hospital.name, hospital.website_url, hospital.hospital_type,
                hospital.region_id, hospital.address, hospital.phone,
                hospital.description, hospital.status, hospital.verified,
                datetime.now(), datetime.now()
            ))
            
            hospital.id = cursor.lastrowid
            conn.commit()
            
            self.logger.info(f"åˆ›å»ºåŒ»é™¢è®°å½•æˆåŠŸ: {hospital.name}")
            return hospital
            
        except Exception as e:
            conn.rollback()
            self.logger.error(f"åˆ›å»ºåŒ»é™¢è®°å½•å¤±è´¥: {e}")
            raise
        finally:
            conn.close()
    
    def update_hospital(self, hospital_id: int, update_data: Dict) -> HospitalInfo:
        """æ›´æ–°åŒ»é™¢ä¿¡æ¯"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        try:
            # 1. è·å–ç°æœ‰è®°å½•
            cursor.execute("SELECT * FROM hospitals WHERE id = ?", (hospital_id,))
            row = cursor.fetchone()
            if not row:
                raise ValueError(f"åŒ»é™¢è®°å½•ä¸å­˜åœ¨: {hospital_id}")
            
            existing_hospital = self._row_to_hospital_info(row)
            
            # 2. åˆå¹¶æ›´æ–°æ•°æ®
            updated_hospital = self._merge_hospital_data(existing_hospital, update_data)
            
            # 3. å¦‚æœå®˜ç½‘URLå‘ç”Ÿå˜åŒ–ï¼Œé‡æ–°éªŒè¯
            if (update_data.get('website_url') and 
                update_data['website_url'] != existing_hospital.website_url):
                
                verification_result = self.verifier.verify_website(
                    SearchResult(
                        hospital_name=updated_hospital.name,
                        website_url=updated_hospital.website_url,
                        source='manual',
                        rank=0,
                        confidence=1.0,
                        search_query='',
                        timestamp=datetime.now()
                    )
                )
                updated_hospital.verified = verification_result.is_verified
            
            # 4. æ›´æ–°æ•°æ®åº“
            cursor.execute("""
                UPDATE hospitals SET 
                    name = ?, website_url = ?, hospital_type = ?, region_id = ?,
                    address = ?, phone = ?, description = ?, status = ?,
                    verified = ?, updated_at = ?
                WHERE id = ?
            """, (
                updated_hospital.name, updated_hospital.website_url,
                updated_hospital.hospital_type, updated_hospital.region_id,
                updated_hospital.address, updated_hospital.phone,
                updated_hospital.description, updated_hospital.status,
                updated_hospital.verified, datetime.now(), hospital_id
            ))
            
            conn.commit()
            self.logger.info(f"æ›´æ–°åŒ»é™¢è®°å½•æˆåŠŸ: {hospital_id}")
            return updated_hospital
            
        except Exception as e:
            conn.rollback()
            self.logger.error(f"æ›´æ–°åŒ»é™¢è®°å½•å¤±è´¥: {e}")
            raise
        finally:
            conn.close()
    
    def delete_hospital(self, hospital_id: int) -> bool:
        """åˆ é™¤åŒ»é™¢è®°å½•"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        try:
            # æ£€æŸ¥æ˜¯å¦æœ‰å…³è”çš„æ‹›æŠ•æ ‡è®°å½•
            cursor.execute(
                "SELECT COUNT(*) FROM tender_records WHERE hospital_id = ?", 
                (hospital_id,)
            )
            tender_count = cursor.fetchone()[0]
            
            if tender_count > 0:
                # æœ‰å…³è”è®°å½•ï¼Œè½¯åˆ é™¤
                cursor.execute("""
                    UPDATE hospitals SET status = 'inactive', updated_at = ?
                    WHERE id = ?
                """, (datetime.now(), hospital_id))
            else:
                # æ— å…³è”è®°å½•ï¼Œç¡¬åˆ é™¤
                cursor.execute("DELETE FROM hospitals WHERE id = ?", (hospital_id,))
            
            conn.commit()
            self.logger.info(f"åˆ é™¤åŒ»é™¢è®°å½•æˆåŠŸ: {hospital_id}")
            return True
            
        except Exception as e:
            conn.rollback()
            self.logger.error(f"åˆ é™¤åŒ»é™¢è®°å½•å¤±è´¥: {e}")
            return False
        finally:
            conn.close()
    
    def get_hospitals(self, filters: Dict = None, pagination: Dict = None) -> List[HospitalInfo]:
        """è·å–åŒ»é™¢åˆ—è¡¨"""
        conn = sqlite3.connect(self.db_path)
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()
        
        try:
            # æ„å»ºæŸ¥è¯¢
            query = """
                SELECT h.*, r.name as region_name
                FROM hospitals h
                LEFT JOIN regions r ON h.region_id = r.id
                WHERE 1=1
            """
            params = []
            
            # åº”ç”¨è¿‡æ»¤å™¨
            if filters:
                if filters.get('region_id'):
                    query += " AND h.region_id = ?"
                    params.append(filters['region_id'])
                
                if filters.get('status'):
                    query += " AND h.status = ?"
                    params.append(filters['status'])
                
                if filters.get('verified'):
                    query += " AND h.verified = ?"
                    params.append(filters['verified'])
                
                if filters.get('hospital_type'):
                    query += " AND h.hospital_type = ?"
                    params.append(filters['hospital_type'])
                
                if filters.get('keyword'):
                    query += " AND (h.name LIKE ? OR h.description LIKE ?)"
                    keyword = f"%{filters['keyword']}%"
                    params.extend([keyword, keyword])
            
            # æ’åº
            query += " ORDER BY h.name ASC"
            
            # åˆ†é¡µ
            if pagination:
                page = pagination.get('page', 1)
                page_size = pagination.get('page_size', 20)
                offset = (page - 1) * page_size
                query += " LIMIT ? OFFSET ?"
                params.extend([page_size, offset])
            
            cursor.execute(query, params)
            hospitals = []
            
            for row in cursor.fetchall():
                hospital = self._row_to_hospital_info(row)
                hospital.region_name = row['region_name']
                hospitals.append(hospital)
            
            return hospitals
            
        finally:
            conn.close()
    
    def discover_hospitals_in_region(self, region_id: int) -> DiscoveryResult:
        """åœ¨æŒ‡å®šåœ°åŒºå‘ç°åŒ»é™¢"""
        self.logger.info(f"å¼€å§‹å‘ç°åœ°åŒº {region_id} çš„åŒ»é™¢")
        
        result = DiscoveryResult(region_id=region_id)
        
        try:
            # 1. è·å–åœ°åŒºä¿¡æ¯
            region_info = self._get_region_info(region_id)
            result.region_name = region_info['name']
            
            # 2. å¤šæ¸ é“æœç´¢åŒ»é™¢
            search_results = self.search_engine.search_hospitals(
                region_info['name'], region_info.get('cities', [])
            )
            result.total_found = len(search_results)
            
            # 3. éªŒè¯æœç´¢ç»“æœ
            verified_results = []
            for search_result in search_results:
                try:
                    verification = self.verifier.verify_website(search_result)
                    if verification.is_verified:
                        verified_results.append(verification)
                    else:
                        result.rejected_count += 1
                except Exception as e:
                    self.logger.warning(f"éªŒè¯æœç´¢ç»“æœå¤±è´¥: {search_result.website_url}")
                    result.error_count += 1
            
            result.verified_count = len(verified_results)
            
            # 4. å»é‡å¤„ç†
            hospital_objects = [self._search_result_to_hospital(v) for v in verified_results]
            deduplicated_hospitals = self.deduplicator.deduplicate_hospitals(hospital_objects)
            result.deduplicated_count = len(deduplicated_hospitals)
            
            # 5. ä¿å­˜åˆ°æ•°æ®åº“
            saved_count = 0
            for hospital in deduplicated_hospitals:
                try:
                    self.create_hospital(hospital.__dict__)
                    saved_count += 1
                    result.saved_hospitals.append(hospital)
                except Exception as e:
                    self.logger.error(f"ä¿å­˜åŒ»é™¢è®°å½•å¤±è´¥: {e}")
                    result.failed_count += 1
            
            result.saved_count = saved_count
            result.status = 'completed'
            
        except Exception as e:
            result.status = 'failed'
            result.error = str(e)
            self.logger.error(f"åœ°åŒºåŒ»é™¢å‘ç°å¤±è´¥: {e}")
        
        return result
    
    def _row_to_hospital_info(self, row) -> HospitalInfo:
        """æ•°æ®åº“è¡Œè½¬æ¢ä¸ºHospitalInfoå¯¹è±¡"""
        return HospitalInfo(
            id=row['id'],
            name=row['name'],
            website_url=row['website_url'],
            hospital_type=row['hospital_type'],
            region_id=row['region_id'],
            address=row['address'],
            phone=row['phone'],
            description=row['description'],
            status=row['status'],
            verified=bool(row['verified']),
            created_at=row['created_at'],
            updated_at=row['updated_at'],
            last_scan_time=row['last_scan_time']
        )
```

### 6.2 æ•°æ®æ¨¡å‹å®šä¹‰

```python
@dataclass
class HospitalInfo:
    """åŒ»é™¢ä¿¡æ¯æ•°æ®æ¨¡å‹"""
    id: Optional[int] = None
    name: str = ""
    website_url: str = ""
    hospital_type: str = "public"
    region_id: int = 0
    address: str = ""
    phone: str = ""
    description: str = ""
    status: str = "active"
    verified: bool = False
    created_at: Optional[datetime] = None
    updated_at: Optional[datetime] = None
    last_scan_time: Optional[datetime] = None
    
    # æ‰©å±•å­—æ®µ
    region_name: str = ""
    tender_count: int = 0
    verification_score: float = 0.0

@dataclass
class VerificationResult:
    """éªŒè¯ç»“æœæ•°æ®æ¨¡å‹"""
    url: str
    hospital_name: str
    overall_score: float
    criteria_scores: Dict[str, float]
    is_verified: bool
    verification_details: Dict[str, Any]

@dataclass
class DiscoveryResult:
    """å‘ç°ç»“æœæ•°æ®æ¨¡å‹"""
    region_id: int
    region_name: str = ""
    total_found: int = 0
    verified_count: int = 0
    deduplicated_count: int = 0
    saved_count: int = 0
    rejected_count: int = 0
    error_count: int = 0
    failed_count: int = 0
    status: str = "pending"
    error: str = ""
    saved_hospitals: List[HospitalInfo] = field(default_factory=list)
```

---

## ğŸ“Š ä¸ƒã€æ€§èƒ½ç›‘æ§ä¸è´¨é‡ä¿è¯

### 7.1 æ€§èƒ½ç›‘æ§

```python
class PerformanceMonitor:
    """æ€§èƒ½ç›‘æ§å™¨"""
    
    def __init__(self, db_path: str):
        self.db_path = db_path
        self.metrics = {}
    
    def record_search_performance(self, search_time: float, result_count: int, 
                                engine_used: str) -> None:
        """è®°å½•æœç´¢æ€§èƒ½"""
        metric = {
            'timestamp': datetime.now(),
            'search_time': search_time,
            'result_count': result_count,
            'engine': engine_used,
            'results_per_second': result_count / search_time if search_time > 0 else 0
        }
        
        self._save_metric('search_performance', metric)
    
    def record_verification_performance(self, verification_time: float, 
                                      is_verified: bool, score: float) -> None:
        """è®°å½•éªŒè¯æ€§èƒ½"""
        metric = {
            'timestamp': datetime.now(),
            'verification_time': verification_time,
            'is_verified': is_verified,
            'score': score,
            'success_rate': 1.0 if is_verified else 0.0
        }
        
        self._save_metric('verification_performance', metric)
    
    def get_performance_report(self, time_range: timedelta) -> Dict:
        """è·å–æ€§èƒ½æŠ¥å‘Š"""
        cutoff_time = datetime.now() - time_range
        
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            
            # æœç´¢æ€§èƒ½ç»Ÿè®¡
            cursor.execute("""
                SELECT engine, 
                       COUNT(*) as search_count,
                       AVG(search_time) as avg_time,
                       AVG(result_count) as avg_results,
                       AVG(results_per_second) as avg_rps
                FROM performance_metrics 
                WHERE metric_type = 'search_performance' 
                AND timestamp > ?
                GROUP BY engine
            """, (cutoff_time,))
            
            search_stats = [dict(row) for row in cursor.fetchall()]
            
            # éªŒè¯æ€§èƒ½ç»Ÿè®¡
            cursor.execute("""
                SELECT 
                    COUNT(*) as verify_count,
                    AVG(verification_time) as avg_time,
                    AVG(score) as avg_score,
                    SUM(success_rate) / COUNT(*) as success_rate
                FROM performance_metrics 
                WHERE metric_type = 'verification_performance'
                AND timestamp > ?
            """, (cutoff_time,))
            
            verify_stats = dict(cursor.fetchone())
            
            return {
                'search_performance': search_stats,
                'verification_performance': verify_stats,
                'generated_at': datetime.now()
            }
    
    def _save_metric(self, metric_type: str, metric: Dict) -> None:
        """ä¿å­˜æ€§èƒ½æŒ‡æ ‡"""
        metric['metric_type'] = metric_type
        
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            cursor.execute("""
                INSERT INTO performance_metrics (
                    metric_type, metric_data, timestamp
                ) VALUES (?, ?, ?)
            """, (metric_type, json.dumps(metric), metric['timestamp']))
```

### 7.2 è´¨é‡ä¿è¯æœºåˆ¶

```python
class QualityController:
    """è´¨é‡æ§åˆ¶å™¨"""
    
    def __init__(self, db_path: str):
        self.db_path = db_path
        self.quality_thresholds = self._load_quality_thresholds()
    
    def validate_hospital_data(self, hospital: HospitalInfo) -> ValidationResult:
        """éªŒè¯åŒ»é™¢æ•°æ®è´¨é‡"""
        result = ValidationResult(
            hospital_id=hospital.id,
            is_valid=True,
            quality_score=0.0,
            issues=[]
        )
        
        # 1. åŸºæœ¬ä¿¡æ¯éªŒè¯
        basic_score = self._validate_basic_info(hospital)
        result.issues.extend(self._get_basic_info_issues(hospital))
        
        # 2. å®˜ç½‘éªŒè¯
        website_score = self._validate_website_info(hospital)
        if website_score < 0.5:
            result.issues.append("å®˜ç½‘ä¿¡æ¯å¯ä¿¡åº¦ä¸è¶³")
        
        # 3. å®Œæ•´æ€§éªŒè¯
        completeness_score = self._validate_data_completeness(hospital)
        
        # 4. ä¸€è‡´æ€§éªŒè¯
        consistency_score = self._validate_data_consistency(hospital)
        
        # è®¡ç®—ç»¼åˆè´¨é‡åˆ†æ•°
        result.quality_score = (
            basic_score * 0.3 +
            website_score * 0.3 +
            completeness_score * 0.2 +
            consistency_score * 0.2
        )
        
        result.is_valid = result.quality_score >= self.quality_thresholds['minimum_quality']
        
        return result
    
    def _validate_basic_info(self, hospital: HospitalInfo) -> float:
        """éªŒè¯åŸºæœ¬ä¿¡æ¯"""
        score = 0.0
        
        # åç§°éªŒè¯
        if hospital.name and len(hospital.name.strip()) >= 3:
            score += 0.3
        
        # åœ°åŒºéªŒè¯
        if hospital.region_id > 0:
            score += 0.2
        
        # ç±»å‹éªŒè¯
        if hospital.hospital_type in ['public', 'private', 'community']:
            score += 0.1
        
        # çŠ¶æ€éªŒè¯
        if hospital.status in ['active', 'inactive', 'closed']:
            score += 0.1
        
        return score
    
    def _validate_website_info(self, hospital: HospitalInfo) -> float:
        """éªŒè¯å®˜ç½‘ä¿¡æ¯"""
        if not hospital.website_url:
            return 0.0
        
        score = 0.0
        
        # URLæ ¼å¼éªŒè¯
        if self._is_valid_url(hospital.website_url):
            score += 0.3
        
        # HTTPSéªŒè¯
        if hospital.website_url.startswith('https://'):
            score += 0.2
        
        # åŸŸåéªŒè¯
        domain = self._extract_domain(hospital.website_url)
        if any(suffix in domain for suffix in ['.gov.cn', '.org.cn', '.cn']):
            score += 0.3
        
        # åŒ»é™¢å…³é”®è¯éªŒè¯
        hospital_keywords = ['hospital', 'yy', 'medical', 'åŒ»é™¢']
        if any(keyword in domain.lower() for keyword in hospital_keywords):
            score += 0.2
        
        return score
```

---

## ğŸ¯ å…«ã€æ€»ç»“

æœ¬åŒ»é™¢å®˜ç½‘è¯†åˆ«çˆ¬è™«ç³»ç»Ÿè®¾è®¡æä¾›äº†ï¼š

### 8.1 æ ¸å¿ƒåŠŸèƒ½
1. **å¤šæ¸ é“æœç´¢** - æœç´¢å¼•æ“ã€å«å¥å§”æ•°æ®ã€æ”¿åºœå®˜ç½‘
2. **æ™ºèƒ½éªŒè¯** - å¤šç»´åº¦çœŸå®æ€§åˆ¤å®šç®—æ³•
3. **åçˆ¬è™«ç­–ç•¥** - åˆè§„çš„è®¿é—®æ§åˆ¶æœºåˆ¶
4. **æ™ºèƒ½å»é‡** - åŸºäºç›¸ä¼¼åº¦ç®—æ³•çš„æ•°æ®å»é‡
5. **å¢é‡æ›´æ–°** - æ™ºèƒ½åŒ–çš„æ•°æ®æ›´æ–°æœºåˆ¶
6. **è´¨é‡ä¿è¯** - å…¨é¢çš„æ•°æ®è´¨é‡éªŒè¯

### 8.2 æŠ€æœ¯ç‰¹ç‚¹
- **åˆè§„å‹å¥½** - ä¸¥æ ¼éµå®ˆrobots.txtï¼Œé™åˆ¶è®¿é—®é¢‘ç‡
- **æ™ºèƒ½è¯†åˆ«** - å¤šç»´åº¦ç½‘ç«™çœŸå®æ€§éªŒè¯
- **é«˜æ€§èƒ½** - å¹¶å‘å¤„ç†ï¼Œç¼“å­˜ä¼˜åŒ–
- **å¯æ‰©å±•** - æ¨¡å—åŒ–è®¾è®¡ï¼Œæ˜“äºæ‰©å±•
- **ç›‘æ§å®Œå–„** - å…¨é¢çš„æ€§èƒ½å’Œè´¨é‡ç›‘æ§

### 8.3 é¢„æœŸæ•ˆæœ
- **è¯†åˆ«å‡†ç¡®ç‡** â‰¥ 85%
- **è¯¯åˆ¤ç‡** â‰¤ 5%
- **è¦†ç›–ç‡** â‰¥ 90%ï¼ˆæœ‰ç‹¬ç«‹å®˜ç½‘çš„åŒ»é™¢ï¼‰
- **æ›´æ–°åŠæ—¶æ€§** â‰¤ 7å¤©

è¯¥ç³»ç»Ÿä¸ºåç»­çš„æ‹›æŠ•æ ‡ç›‘æ§æä¾›äº†å¯é ã€å‡†ç¡®çš„åŒ»é™¢å®˜ç½‘æ•°æ®åŸºç¡€ï¼Œç¡®ä¿ç›‘æ§ç›®æ ‡çš„è´¨é‡å’Œè¦†ç›–é¢ã€‚

**ä¸‹ä¸€æ­¥ï¼š** åŸºäºæ­¤è®¾è®¡æ–¹æ¡ˆï¼Œå®ç°å…·ä½“çš„ä»£ç æ¨¡å—å’Œé›†æˆæµ‹è¯•ã€‚